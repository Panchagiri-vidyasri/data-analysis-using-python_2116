{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvHvF8zTUz38+GnlDPVDw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panchagiri-vidyasri/data-analysis-using-python_2116/blob/main/2203a52116_daup_lab12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import ttest_1samp, chi2_contingency\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Student_Mental_Stress_and_Coping_Mechanisms.csv\")\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "target_col = None\n",
        "for col in df.columns:\n",
        "    if \"stress\" in col.lower():\n",
        "        target_col = col\n",
        "        break\n",
        "\n",
        "if target_col is None:\n",
        "    raise KeyError(\"Mental stress level column not found in dataset. Check dataset structure.\")\n",
        "\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "        \"F1-score\": f1_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n",
        "\n",
        "# Feature importance from Random Forest\n",
        "rf = models[\"Random Forest\"]\n",
        "importances = rf.feature_importances_\n",
        "important_features = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Top 3 most important features:\")\n",
        "print(important_features.head(3))\n",
        "\n",
        "# PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mkTyURWfnCd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01478ec0-e77f-4971-d510-503918de218b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy  Precision    Recall  F1-score\n",
            "Logistic Regression  0.210526   0.196597  0.210526  0.198562\n",
            "Random Forest        0.157895   0.168216  0.157895  0.157918\n",
            "SVM                  0.164474   0.169806  0.164474  0.160504\n",
            "Top 3 most important features:\n",
            "Student ID              0.097560\n",
            "Study Hours Per Week    0.089673\n",
            "Age                     0.068711\n",
            "dtype: float64\n",
            "Explained variance ratio: [0.99183725 0.0066955 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-sample T-test\n",
        "t_stat, p_value = ttest_1samp(y, 5)\n",
        "print(\"T-test p-value:\", p_value)\n",
        "\n",
        "sample1 = np.random.normal(50, 10, 100)\n",
        "sample2 = np.random.normal(52, 10, 100)\n",
        "z_stat, p_value = ztest(sample1, sample2)\n",
        "print(f\"Z-Test: Z-stat = {z_stat:.2f}, p-value = {p_value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6qLviQbBiKd",
        "outputId": "2860ed34-8f4d-412e-c663-0d35519602e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-test p-value: 2.905158136943706e-175\n",
            "Z-Test: Z-stat = -1.05, p-value = 0.2934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def chi_square_test(observed):\n",
        "\n",
        "    observed = np.array(observed)\n",
        "    chi2_stat, p_value, dof, expected = stats.chi2_contingency(observed)\n",
        "    return chi2_stat, p_value, dof, expected\n",
        "\n",
        "# Example usage:\n",
        "observed_data = [[50, 30], [20, 40]]  # Example contingency table\n",
        "chi2_stat, p_value, dof, expected = chi_square_test(observed_data)\n",
        "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"Expected Frequencies: \\n{expected}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmQ0Ux5RAaUW",
        "outputId": "b1a8150c-4705-4a2b-9707-ce7fd861cca1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Statistic: 10.529166666666667\n",
            "P-Value: 0.0011750518530845063\n",
            "Degrees of Freedom: 1\n",
            "Expected Frequencies: \n",
            "[[40. 40.]\n",
            " [30. 30.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YN1rThBqET0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}